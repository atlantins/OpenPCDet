{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=torch.Tensor([[1,2,3,4],\n",
    "                [2,3,4,5],\n",
    "                 [7,8,9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =lst.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_atten=nn.MultiheadAttention(embed_dim=4,\n",
    "                                  num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0817,  0.8499,  0.5107, -1.4308]],\n",
       " \n",
       "         [[-1.2068,  0.8185,  0.5901, -1.4901]],\n",
       " \n",
       "         [[-1.7884,  0.5670,  0.5783, -1.3496]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[0.1678, 0.1947, 0.6375],\n",
       "          [0.1247, 0.1502, 0.7251],\n",
       "          [0.0299, 0.0466, 0.9235]]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_atten(lst,lst,lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = defaultdict(lambda : 0 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rec1[\u001b[39m'\u001b[39;49m\u001b[39mc\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "rec1['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = collections.Counter('abcdfgdgdfgdfgdg')\n",
    "c2 = collections.Counter('dddbca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = c1 - c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'g': 5, 'f': 3, 'd': 2})\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'d': 2, 'f': 3, 'g': 5})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSum(nums, target):\n",
    "    records = dict()\n",
    "    for index, value in enumerate(nums):  \n",
    "        if target - value in records:   # 遍历当前元素，并在map中寻找是否有匹配的key\n",
    "            return [records[target- value], index]\n",
    "        records[value] = index    # 遍历当前元素，并在map中寻找是否有匹配的key\n",
    "    print(records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [5,4,3,2,1,0,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = twoSum(nums=nums,target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'end'\n",
    "res = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'n', 'd']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'n', 'd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "\n",
    "class ConvAttentionLayer_Decouple(nn.Module):\n",
    "    def __init__(self, input_channels: int, numhead: int = 1, reduction_ratio=2):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input_channels (int): input channel of conv attention\n",
    "            numhead (int, optional): the number of attention heads. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.q_conv = nn.Conv2d(input_channels, input_channels // reduction_ratio, 3, 1, 1)\n",
    "        self.q_sem_conv = nn.Conv2d(input_channels,\n",
    "                                    input_channels // reduction_ratio, 3, 1, 1)\n",
    "        self.q_geo_conv = nn.Conv2d(input_channels,\n",
    "                                    input_channels // reduction_ratio, 3, 1, 1)\n",
    "        # self.k_conv = nn.Conv2d(input_channels, input_channels // reduction_ratio, 3, 1, 1)\n",
    "        self.k_sem_conv = nn.Conv2d(input_channels,\n",
    "                                    input_channels // reduction_ratio, 3, 1, 1)\n",
    "        self.k_geo_conv = nn.Conv2d(input_channels,\n",
    "                                    input_channels // reduction_ratio, 3, 1, 1)\n",
    "        # self.v_conv = nn.Conv2d(input_channels, input_channels, 3, 1, 1)\n",
    "        self.v_conv = nn.Conv2d(input_channels, input_channels, 1, 1, 0)\n",
    "        self.out_sem_conv = nn.Conv2d(input_channels, input_channels, 1, 1)\n",
    "        self.out_geo_conv = nn.Conv2d(input_channels, input_channels, 1, 1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.channels = input_channels // reduction_ratio\n",
    "        self.numhead = numhead\n",
    "        self.head_dim = self.channels // numhead\n",
    "        self.sem_norm = nn.LayerNorm(input_channels)\n",
    "        self.geo_norm = nn.LayerNorm(input_channels)\n",
    "\n",
    "    def forward(self,\n",
    "                query: torch.Tensor,\n",
    "                key: torch.Tensor,\n",
    "                value: torch.Tensor,\n",
    "                q_pos_emb: Optional[torch.Tensor] = None,\n",
    "                k_pos_emb: Optional[torch.Tensor] = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            query (torch.Tensor, [B, C, H_qk, W_qk]): feature of query\n",
    "            key (torch.Tensor, [B, C, H_qk, W_qk]): feature of key\n",
    "            value (torch.Tensor, [B, C, H_v, W_v]): feature of value\n",
    "            q_pos_emb (Optional[torch.Tensor], optional, [[B, C, H_q, W_q]]):\n",
    "                positional encoding. Defaults to None.\n",
    "            k_pos_emb (Optional[torch.Tensor], optional, [[B, C, H_kv, W_kv]]):\n",
    "                positional encoding. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        view = query + 0  # NOTE: a funny method to deepcopy\n",
    "        input_channel = view.shape[1]\n",
    "        if q_pos_emb is not None:\n",
    "            query += q_pos_emb\n",
    "        if k_pos_emb is not None:\n",
    "            key += k_pos_emb\n",
    "\n",
    "        # to qkv forward\n",
    "        # q = self.q_conv(query)\n",
    "        q_sem = self.q_sem_conv(query) # [B,C/reduction_ratio,H_qk,W_qk]\n",
    "        q_geo = self.q_geo_conv(query) # \n",
    "        qs = [q_sem, q_geo]\n",
    "        # k = self.k_conv(key)\n",
    "        k_sem = self.k_sem_conv(key) # [B,C/reduction_ratio,H_qk,W_qk]\n",
    "        k_geo = self.k_geo_conv(key)\n",
    "        ks = [k_sem, k_geo]\n",
    "        v = self.v_conv(value)\n",
    "        vs = [v, v]\n",
    "        out_convs = [self.out_sem_conv, self.out_geo_conv]\n",
    "        norms = [self.sem_norm, self.geo_norm]\n",
    "        outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for q, k, v, out_conv, norm in zip(qs, ks, vs, out_convs, norms):\n",
    "\n",
    "            '''\n",
    "            query (torch.Tensor, [B, C/reduction_ratio, H_q, W_q]): feature of query\n",
    "            key (torch.Tensor, [B, C/reduction_ratio, H_kv, W_kv]): feature of key\n",
    "            value (torch.Tensor, [B, C, H_v, W_v]): feature of value\n",
    "            '''\n",
    "\n",
    "            # read shape of qkv\n",
    "            bs = q.shape[0]\n",
    "            qk_channel = q.shape[1]  # equal to the channel of `k`\n",
    "            v_channel = v.shape[1]  # channel of `v`\n",
    "            h_q, w_q = q.shape[2:]  # height and weight of query map\n",
    "            h_kv, w_kv = k.shape[2:]  # height and weight of key and value map\n",
    "            numhead = self.numhead\n",
    "            qk_head_dim = qk_channel // numhead\n",
    "            v_head_dim = v_channel // numhead\n",
    "\n",
    "            # scale query\n",
    "            scaling = float(self.head_dim) ** -0.5\n",
    "            q = q * scaling\n",
    "\n",
    "            # reshape(sequentialize) qkv\n",
    "            # B, C, H_qk, W_qk\n",
    "            q = rearrange(q, \"b c h w -> b c (h w)\", b=bs, c=qk_channel, h=h_q, w=w_q)  \n",
    "            q = rearrange(q, \"b (n d) (h w) -> (b n) (h w) d\", b=bs,\n",
    "                          n=numhead, h=h_q, w=w_q, d=qk_head_dim)  # b*n,h_q*w_q,qk_head_dim\n",
    "            q = q.contiguous()\n",
    "            # B, C, H_qk, W_qk\n",
    "            k = rearrange(k, \"b c h w -> b c (h w)\", b=bs, c=qk_channel, h=h_kv, w=w_kv)\n",
    "            k = rearrange(k, \"b (n d) (h w) -> (b n) (h w) d\", b=bs,\n",
    "                          n=numhead, h=h_kv, w=w_kv, d=qk_head_dim) # b*n,h_kv*w_kv,qk_head_dim\n",
    "            k = k.contiguous()\n",
    "            v = rearrange(v, \"b c h w -> b c (h w)\", b=bs, c=v_channel, h=h_kv, w=w_kv)\n",
    "            v = rearrange(v, \"b (n d) (h w) -> (b n) (h w) d\", b=bs,\n",
    "                          n=numhead, h=h_kv, w=w_kv, d=v_head_dim)\n",
    "            v = v.contiguous()\n",
    "\n",
    "            # get the attention map\n",
    "            energy = torch.bmm(q, k.transpose(1, 2))  # [h_q*w_q, h_kv*w_kv]\n",
    "            attention = F.softmax(energy, dim=-1)  # [h_q*w_q, h_kv*w_kv]\n",
    "            attentions.append(attention)\n",
    "            # get the attention output\n",
    "            r = torch.bmm(attention, v)  # [bs * nhead, h_q*w_q, C']\n",
    "            r = rearrange(r, \"(b n) (h w) d -> b (n d) h w\", b=bs,\n",
    "                          n=numhead, h=h_q, w=w_q, d=v_head_dim)\n",
    "            r = r.contiguous()\n",
    "            r = out_conv(r)\n",
    "\n",
    "            # residual\n",
    "            temp_view = view + r\n",
    "            temp_view = temp_view.view(bs, input_channel, -1).permute(2, 0, 1).contiguous() # [B, C, H_qk, W_qk]\n",
    "            temp_view = norm(temp_view)\n",
    "            outputs.append(temp_view)\n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= 'we are the hero'\n",
    "counter = s.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w', 'e', ' ', 'a', 'r', 'e', ' ', 't', 'h', 'e', ' ', 'h', 'e', 'r', 'o']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.extend([' ']*counter*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'o',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
